slug: operatorframework-go-operator-memcached
id: sdmc3ppgqg2x
type: track
title: Operator SDK with Go, Memcached
description: |
  ## Why an Operator?

  Operators make it easy to manage complex stateful applications on top of Kubernetes. However writing an Operator today can be difficult because of challenges such as using low level APIs, writing boilerplate, and a lack of modularity which leads to duplication.

  ## What is the Operator SDK?

  The Operator SDK is a framework that uses the controller-runtime library to make writing Operators easier by providing:

  * High level APIs and abstractions to write the operational logic more intuitively.
  * Tools for scaffolding and code generation to bootstrap a new project fast.
  * Extensions to cover common Operator use cases.

  ## How do I use it?

  The following is the workflow for a new **Go-based** Operator with the Operator SDK:

  1. Create a new Operator project using the SDK CLI.
  2. Create a new Custom Resource Definition **API Type** using the SDK CLI.
  3. Add your Custom Resource Definition (CRD) to your live Kubernetes cluster.
  4. Define your Custom Resource Spec and Status.
  5. Create a new Controller for your Custom Resource Definition API.
  6. Write the reconciling logic for your Controller.
  7. Run the Operator locally to test your code against your live Kubernetes cluster.
  8. Add your Custom Resource (CR) to your live Kubernetes cluster and watch your Operator in action!
  9. After you are satisifed with your work, run some Makefile commands to build and generate the Operator Deployment manifests.
  10. Optionally add additional APIs and Controllers using the SDK CLI.

  ## Memcached Operator

  In this tutorial, we will create an Operator called a Memcached. A Memcached is a simple Controller/Operator that will do the following :

  1. Create a Memcached Deployment if it doesn't exist
  2. Ensure that the Deployment size is the same as specified in `spec.size`
  3. Update the Memcached CR status using the status writer with the names of the CR's pods

  Let's begin!
icon: https://logodix.com/logo/1910931.png
level: beginner
tags:
- openshift
owner: openshift
developers:
- btannous@redhat.com
- nvinto@redhat.com
- rjarvine@redhat.com
private: false
published: true
challenges:
- slug: step1
  id: ofohoku6axoy
  type: challenge
  title: Creating a New Project
  assignment: |
    Let's begin by creating a new project called `myproject`:

    ```
    oc new-project myproject
    ```
    `
    ```
    <br>
    Let's now create a new directory for our project:

    ```
    mkdir -p $HOME/projects/memcached-operator
    ```
    `
    ```
    <br>
    Navigate to the directory:

    ```
    cd $HOME/projects/memcached-operator
    ```
    `
    ```
    <br>
    Initialize a new Go-based Operator SDK project for the Memcached Operator:

    ```
    operator-sdk init --domain example.com --repo github.com/example/memcached-operator
    ```
    `
    ```
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step2
  id: 5mouxtcdmmow
  type: challenge
  title: Create a new API and Controller
  assignment: |
    Add a new Custom Resource Definition (CRD) API called Memcached with APIVersion `cache.example.com/v1alpha1` and Kind `Memcached`. This command will also create our boilerplate controller logic and [Kustomize](https://kustomize.io) configuration files.

    ```
    operator-sdk create api --group cache --version v1alpha1 --kind Memcached --resource --controller
    ```
    `
    ```
    <br>

    We should now see the /api, config, and /controllers directories.

    **Note:** This guide will cover the default case of a single group API. If you would like to support Multi-Group APIs see the [Single Group to Multi-Group](https://book.kubebuilder.io/migration/multi-group.html) doc.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step3
  id: ufjqwgczvcay
  type: challenge
  title: Defining the Spec and Status
  assignment: "Let's begin by inspecting the newly generated `api/v1alpha1/memcached_types.go` file for our Memcached API:\n\n```\ncat api/v1alpha1/memcached_types.go\n```\n`\n```\n\nIn Kubernetes, every functional object (with some exceptions, i.e. ConfigMap) includes `spec` and `status`. Kubernetes functions by reconciling desired state (Spec) with the actual cluster state. We then record what is observed (Status).\n\nAlso observe the `+kubebuilder` comment markers found throughout the file. `operator-sdk` makes use of a tool called [controler-gen](https://github.com/kubernetes-sigs/controller-tools) (from the [controller-tools](https://github.com/kubernetes-sigs/controller-tools) project) for generating utility code and Kubernetes YAML. More information on markers for config/code generation can be found [here](https://book.kubebuilder.io/reference/markers.html).\n\nLet's now modify the `MemcachedSpec` and `MemcachedStatus` of the `Memcached` Custom Resource (CR) at `api/v1alpha1/memcached_types.go`\n\n<br>\nIt should look like the file below:\n\n<pre class=\"file\">\npackage v1alpha1\n\nimport (\n        metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n)\n\n// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!\n// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.\n\n// MemcachedSpec defines the desired state of Memcached\ntype MemcachedSpec struct {\n\t// +kubebuilder:validation:Minimum=0\n\t// Size is the size of the memcached deployment\n\tSize int32 `json:\"size\"`\n}\n\n// MemcachedStatus defines the observed state of Memcached\ntype MemcachedStatus struct {\n\t// Nodes are the names of the memcached pods\n\tNodes []string `json:\"nodes\"`\n}\n</pre>\n\nAdd the `+kubebuilder:subresource:status` [marker](https://book.kubebuilder.io/reference/generating-crd.html#status) to add a [status subresource](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#status-subresource) to the CRD manifest so that the controller can update the CR status without changing the rest of the CR object:\n\n<pre class=\"file\">\n// Memcached is the Schema for the memcacheds API\n// +kubebuilder:printcolumn:JSONPath=\".spec.size\",name=Desired,type=string\n// +kubebuilder:printcolumn:JSONPath=\".status.nodes\",name=Nodes,type=string\n// +kubebuilder:subresource:status\ntype Memcached struct {\n\tmetav1.TypeMeta   `json:\",inline\"`\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n\tSpec   MemcachedSpec   `json:\"spec,omitempty\"`\n\tStatus MemcachedStatus `json:\"status,omitempty\"`\n}\n\nfunc init() {\n\tSchemeBuilder.Register(&Memcached{}, &MemcachedList{})\n}\n\n</pre>\n\nYou can easily update this file by running the following command:\n\n```\n\\cp /tmp/memcached_types.go api/v1alpha1/memcached_types.go\n```\n`\n```\n<br>\nAfter modifying the `*_types.go` file, always run the following command to update the `zz_generated.deepcopy.go` file:\n\n```\nmake generate\n```\n`\n```\n<br>\n\nThe above makefile target will invoke the controller-gen utility to update the api/v1alpha1/zz_generated.deepcopy.go file to ensure our API’s Go type definitons implement the runtime.Object interface that all Kind types must implement.\n\n\nNow we can run the `make manifests` command to generate our customized CRD and additional object YAMLs.\n\n```\nmake manifests\n```\n`\n```\n<br>\n\nThis makefile target will invoke controller-gen to generate the CRD manifests at config/crd/bases/cache.example.com_memcacheds.yaml.\n\n\n\nThanks to our comment markers, observe that we now have a newly generated CRD yaml that reflects the `spec.size` and `status.nodes` OpenAPI v3 schema validation and customized print columns.\n\n```\ncat config/crd/bases/cache.example.com_memcacheds.yaml\n```\n`\n```\n<br>\nDeploy your Memcached Custom Resource Definition to the live OpenShift Cluster:\n\n```\noc apply -f config/crd/bases/cache.example.com_memcacheds.yaml\n```\n`\n```\n<br>\nConfirm the CRD was successfully created:\n\n```\noc get crd memcacheds.cache.example.com -o yaml\n```\n`\n```\n"
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step4
  id: cb0adaurktwx
  type: challenge
  title: Customizing the Operator Logic
  assignment: "\n**Note:** The next two subsections explain how the controller watches resources and how the reconcile loop is triggered.\n\nLet's now observe the default `controllers/memcached_controller.go` file:\n\n```\ncat controllers/memcached_controller.go\n```\n`\n```\n\nThis default controller requires additional logic so we can trigger our reconciler whenever `kind: Memcached` objects are added, updated, or deleted. We also want to trigger the reconciler whenever Deployment owned by a given Memcached are added, updated, and deleted as well. To accomplish this. we modify the controller's `SetupWithManager` method.\n\nFor this example replace the generated controller at `controllers/memcached_controller.go` with the following code.\n\n<pre class=\"file\">\n\npackage controllers\n\nimport (\n\tappsv1 \"k8s.io/api/apps/v1\"\n\tcorev1 \"k8s.io/api/core/v1\"\n\t\"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/types\"\n\t\"reflect\"\n\t\"time\"\n\n\t\"context\"\n\n\t\"k8s.io/apimachinery/pkg/runtime\"\n\tctrl \"sigs.k8s.io/controller-runtime\"\n\t\"sigs.k8s.io/controller-runtime/pkg/client\"\n\tctrllog \"sigs.k8s.io/controller-runtime/pkg/log\"\n\n\tcachev1alpha1 \"github.com/example/memcached-operator/api/v1alpha1\"\n)\n\n// MemcachedReconciler reconciles a Memcached object\ntype MemcachedReconciler struct {\n\tclient.Client\n\tScheme *runtime.Scheme\n}\n\n//+kubebuilder:rbac:groups=cache.example.com,resources=memcacheds,verbs=get;list;watch;create;update;patch;delete\n//+kubebuilder:rbac:groups=cache.example.com,resources=memcacheds/status,verbs=get;update;patch\n//+kubebuilder:rbac:groups=cache.example.com,resources=memcacheds/finalizers,verbs=update\n//+kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;watch;create;update;patch;delete\n//+kubebuilder:rbac:groups=core,resources=pods,verbs=get;list;watch\n\n// Reconcile is part of the main kubernetes reconciliation loop which aims to\n// move the current state of the cluster closer to the desired state.\n// TODO(user): Modify the Reconcile function to compare the state specified by\n// the Memcached object against the actual cluster state, and then\n// perform operations to make the cluster state reflect the state specified by\n// the user.\n//\n// For more details, check Reconcile and its Result here:\n// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.8.3/pkg/reconcile\nfunc (r *MemcachedReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n\tlog := ctrllog.FromContext(ctx)\n\n\t// Fetch the Memcached instance\n\tmemcached := &cachev1alpha1.Memcached{}\n\terr := r.Get(ctx, req.NamespacedName, memcached)\n\tif err != nil {\n\t\tif errors.IsNotFound(err) {\n\t\t\t// Request object not found, could have been deleted after reconcile request.\n\t\t\t// Owned objects are automatically garbage collected. For additional cleanup logic use finalizers.\n\t\t\t// Return and don't requeue\n\t\t\tlog.Info(\"Memcached resource not found. Ignoring since object must be deleted\")\n\t\t\treturn ctrl.Result{}, nil\n\t\t}\n\t\t// Error reading the object - requeue the request.\n\t\tlog.Error(err, \"Failed to get Memcached\")\n\t\treturn ctrl.Result{}, err\n\t}\n\n\t// Check if the deployment already exists, if not create a new one\n\tfound := &appsv1.Deployment{}\n\terr = r.Get(ctx, types.NamespacedName{Name: memcached.Name, Namespace: memcached.Namespace}, found)\n\tif err != nil && errors.IsNotFound(err) {\n\t\t// Define a new deployment\n\t\tdep := r.deploymentForMemcached(memcached)\n\t\tlog.Info(\"Creating a new Deployment\", \"Deployment.Namespace\", dep.Namespace, \"Deployment.Name\", dep.Name)\n\t\terr = r.Create(ctx, dep)\n\t\tif err != nil {\n\t\t\tlog.Error(err, \"Failed to create new Deployment\", \"Deployment.Namespace\", dep.Namespace, \"Deployment.Name\", dep.Name)\n\t\t\treturn ctrl.Result{}, err\n\t\t}\n\t\t// Deployment created successfully - return and requeue\n\t\treturn ctrl.Result{Requeue: true}, nil\n\t} else if err != nil {\n\t\tlog.Error(err, \"Failed to get Deployment\")\n\t\treturn ctrl.Result{}, err\n\t}\n\n\t// Ensure the deployment size is the same as the spec\n\tsize := memcached.Spec.Size\n\tif *found.Spec.Replicas != size {\n\t\tfound.Spec.Replicas = &size\n\t\terr = r.Update(ctx, found)\n\t\tif err != nil {\n\t\t\tlog.Error(err, \"Failed to update Deployment\", \"Deployment.Namespace\", found.Namespace, \"Deployment.Name\", found.Name)\n\t\t\treturn ctrl.Result{}, err\n\t\t}\n\t\t// Ask to requeue after 1 minute in order to give enough time for the\n\t\t// pods be created on the cluster side and the operand be able\n\t\t// to do the next update step accurately.\n\t\treturn ctrl.Result{RequeueAfter: time.Minute}, nil\n\t}\n\n\t// Update the Memcached status with the pod names\n\t// List the pods for this memcached's deployment\n\tpodList := &corev1.PodList{}\n\tlistOpts := []client.ListOption{\n\t\tclient.InNamespace(memcached.Namespace),\n\t\tclient.MatchingLabels(labelsForMemcached(memcached.Name)),\n\t}\n\tif err = r.List(ctx, podList, listOpts...); err != nil {\n\t\tlog.Error(err, \"Failed to list pods\", \"Memcached.Namespace\", memcached.Namespace, \"Memcached.Name\", memcached.Name)\n\t\treturn ctrl.Result{}, err\n\t}\n\tpodNames := getPodNames(podList.Items)\n\n\t// Update status.Nodes if needed\n\tif !reflect.DeepEqual(podNames, memcached.Status.Nodes) {\n\t\tmemcached.Status.Nodes = podNames\n\t\terr := r.Status().Update(ctx, memcached)\n\t\tif err != nil {\n\t\t\tlog.Error(err, \"Failed to update Memcached status\")\n\t\t\treturn ctrl.Result{}, err\n\t\t}\n\t}\n\n\treturn ctrl.Result{}, nil\n}\n\n// deploymentForMemcached returns a memcached Deployment object\nfunc (r *MemcachedReconciler) deploymentForMemcached(m *cachev1alpha1.Memcached) *appsv1.Deployment {\n\tls := labelsForMemcached(m.Name)\n\treplicas := m.Spec.Size\n\n\tdep := &appsv1.Deployment{\n\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\tName:      m.Name,\n\t\t\tNamespace: m.Namespace,\n\t\t},\n\t\tSpec: appsv1.DeploymentSpec{\n\t\t\tReplicas: &replicas,\n\t\t\tSelector: &metav1.LabelSelector{\n\t\t\t\tMatchLabels: ls,\n\t\t\t},\n\t\t\tTemplate: corev1.PodTemplateSpec{\n\t\t\t\tObjectMeta: metav1.ObjectMeta{\n\t\t\t\t\tLabels: ls,\n\t\t\t\t},\n\t\t\t\tSpec: corev1.PodSpec{\n\t\t\t\t\tContainers: []corev1.Container{{\n\t\t\t\t\t\tImage:   \"memcached:1.4.36-alpine\",\n\t\t\t\t\t\tName:    \"memcached\",\n\t\t\t\t\t\tCommand: []string{\"memcached\", \"-m=64\", \"-o\", \"modern\", \"-v\"},\n\t\t\t\t\t\tPorts: []corev1.ContainerPort{{\n\t\t\t\t\t\t\tContainerPort: 11211,\n\t\t\t\t\t\t\tName:          \"memcached\",\n\t\t\t\t\t\t}},\n\t\t\t\t\t}},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\t// Set Memcached instance as the owner and controller\n\tctrl.SetControllerReference(m, dep, r.Scheme)\n\treturn dep\n}\n\n// labelsForMemcached returns the labels for selecting the resources\n// belonging to the given memcached CR name.\nfunc labelsForMemcached(name string) map[string]string {\n\treturn map[string]string{\"app\": \"memcached\", \"memcached_cr\": name}\n}\n\n// getPodNames returns the pod names of the array of pods passed in\nfunc getPodNames(pods []corev1.Pod) []string {\n\tvar podNames []string\n\tfor _, pod := range pods {\n\t\tpodNames = append(podNames, pod.Name)\n\t}\n\treturn podNames\n}\n\n// SetupWithManager sets up the controller with the Manager.\nfunc (r *MemcachedReconciler) SetupWithManager(mgr ctrl.Manager) error {\n\treturn ctrl.NewControllerManagedBy(mgr).\n\t\tFor(&cachev1alpha1.Memcached{}).\n\t\tOwns(&appsv1.Deployment{}).\n\t\tComplete(r)\n}\n</pre>\n\nYou can easily update this file by running the following command:\n\n```\n\\cp /tmp/memcached_controller.go controllers/memcached_controller.go\n```\n`\n```\n\n`go mod tidy`  ensures that the go.mod file matches the source code in the module. It adds any missing module requirements necessary to build the current module's packages and dependencies, and it removes requirements on modules that don't provide any relevant packages. It also adds any missing entries to go.sum and removes unnecessary entries.\n\n```\ngo mod tidy\n```\n`\n```\n\n\n"
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step5
  id: m1oxymio6ep5
  type: challenge
  title: Resources watched by the Controller
  assignment: "**Note:** The next two subsections explain how the controller watches resources and how the reconcile loop is triggered. If you’d like to skip this section, head to the deploy section to see how to run the operator.\n\n```\ncat controllers/memcached_controller.go\n```\n`\n```\n\nThe `SetupWithManager()` function in `controllers/memcached_controller.go` specifies how the controller is built to watch a CR and other resources that are owned and managed by that controller.\n\n<pre class=\"file\">\nimport (\n\t...\n\tappsv1 \"k8s.io/api/apps/v1\"\n\t...\n)\n\nfunc (r *MemcachedReconciler) SetupWithManager(mgr ctrl.Manager) error {\n\treturn ctrl.NewControllerManagedBy(mgr).\n\t\tFor(&cachev1alpha1.Memcached{}).\n\t\tOwns(&appsv1.Deployment{}).\n\t\tComplete(r)\n}\n</pre>\n\nThe `NewControllerManagedBy()` provides a controller builder that allows various controller configurations.\n\n`For(&cachev1alpha1.Memcached{})` specifies the Memcached type as the primary resource to watch. For each Memcached type Add/Update/Delete event the reconcile loop will be sent a reconcile `Request` (a namespace/name key) for that Memcached object.\n\n`Owns(&appsv1.Deployment{})` specifies the Deployments type as the secondary resource to watch. For each Deployment type Add/Update/Delete event, the event handler will map each event to a reconcile Request for the owner of the Deployment. Which in this case is the Memcached object for which the Deployment was created.\n\n\n\n"
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step6
  id: gtyvqh8vkhsy
  type: challenge
  title: Controller Configurations
  assignment: |
    There are a number of other useful configurations that can be made when initialzing a controller. For more details on these configurations consult the upstream [builder](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/builder#example-Builder) and [controller](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/controller) godocs.

    * Set the max number of concurrent Reconciles for the controller via the [MaxConcurrentReconciles](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/controller#Options) option. Defaults to 1.

    <pre class="file">
    func (r *MemcachedReconciler) SetupWithManager(mgr ctrl.Manager) error {
      return ctrl.NewControllerManagedBy(mgr).
        For(&cachev1alpha1.Memcached{}).
        Owns(&appsv1.Deployment{}).
        WithOptions(controller.Options{MaxConcurrentReconciles: 2}).
        Complete(r)
    }
    </pre>

    * Filter watch events using [predicates](https://sdk.operatorframework.io/docs/building-operators/golang/references/event-filtering/)

    * Choose the type of [EventHandler](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/handler#hdr-EventHandlers) to change how a watch event will translate to reconcile requests for the reconcile loop. For operator relationships that are more complex than primary and secondary resources, the [EnqueueRequestsFromMapFunc](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/handler#EnqueueRequestsFromMapFunc) handler can be used to transform a watch event into an arbitrary set of reconcile requests.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step7
  id: joklfz7msakk
  type: challenge
  title: Reconcile loop
  assignment: "The reconcile function is responsible for enforcing the desired CR state on the actual state of the system. It runs each time an event occurs on a watched CR or resource, and will return some value depending on whether those states match or not.\n\nIn this way, every Controller has a Reconciler object with a Reconcile() method that implements the reconcile loop. The reconcile loop is passed the [Request](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Request) argument which is a Namespace/Name key used to lookup the primary resource object, Memcached, from the cache:\n\n<pre class=\"file\">\nimport (\n\tctrl \"sigs.k8s.io/controller-runtime\"\n\n\tcachev1alpha1 \"github.com/example/memcached-operator/api/v1alpha1\"\n\t...\n)\n\nfunc (r *MemcachedReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n  _ = context.Background()\n  ...\n\n  // Lookup the Memcached instance for this reconcile request\n  memcached := &cachev1alpha1.Memcached{}\n  err := r.Get(ctx, req.NamespacedName, memcached)\n  ...\n}\n</pre>\n\nFor a guide on Reconcilers, Clients, and interacting with resource Events, see the [Client API doc](https://sdk.operatorframework.io/docs/building-operators/golang/references/client/).\n\n\n\n"
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step8
  id: afazbxzzz5ry
  type: challenge
  title: 'Return options for a Reconciler:'
  assignment: |+
    The following are a few possible return options for a Reconciler:

    * With the error:
    <pre class="file">
    return ctrl.Result{}, err
    </pre>
    * Without an error:
    <pre class="file">
    return ctrl.Result{Requeue: true}, nil
    </pre>
    * Therefore, to stop the Reconcile, use:
    <pre class="file">
    return ctrl.Result{}, nil
    </pre>
    * Reconcile again after X time:
    <pre class="file">
     return ctrl.Result{RequeueAfter: nextRun.Sub(r.Now())}, nil
     </pre>
    For more details, check the Reconcile and its [Reconcile godoc](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile).

  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step9
  id: eurgfy8xtjre
  type: challenge
  title: Specify permissions and generate RBAC manifests
  assignment: |
    The controller needs certain [RBAC](https://kubernetes.io/docs/reference/access-authn-authz/rbac/) permissions to interact with the resources it manages. These are specified via [RBAC markers](https://book.kubebuilder.io/reference/markers/rbac.html) like the following:

    <pre class="file">
    //+kubebuilder:rbac:groups=cache.example.com,resources=memcacheds,verbs=get;list;watch;create;update;patch;delete
    //+kubebuilder:rbac:groups=cache.example.com,resources=memcacheds/status,verbs=get;update;patch
    //+kubebuilder:rbac:groups=cache.example.com,resources=memcacheds/finalizers,verbs=update
    //+kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;watch;create;update;patch;delete
    //+kubebuilder:rbac:groups=core,resources=pods,verbs=get;list;

    func (r *MemcachedReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
      ...
    }
    </pre>

    The `ClusterRole` manifest at `config/rbac/role.yaml` is generated from the above markers via controller-gen with the following command:

    ```
    make manifests
    ```
    `
    ```
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step10
  id: pyvezbqwq93t
  type: challenge
  title: Running the Operator Locally (Outside the Cluster)
  assignment: |-
    Once the CRD is registered, there are two ways to run the Operator:

    * As a Pod inside a Kubernetes cluster
    * As a Go program outside the cluster using Operator-SDK. This is great for local development of your Operator.

    For the sake of this tutorial, we will run the Operator as a Go program outside the cluster using Operator-SDK and our `kubeconfig` credentials

    Once running, the command will block the current session. You can continue interacting with the OpenShift cluster by opening a new terminal window. You can quit the session by pressing `CTRL + C`.

    ```
    WATCH_NAMESPACE=myproject make run
    ```
    `
    ```
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step11
  id: dyxbnuy11sdg
  type: challenge
  title: Creating the Memcached Custom Resource
  assignment: |
    In a new terminal, inspect the Custom Resource manifest:

    ```
    cd $HOME/projects/memcached-operator
    cat config/samples/cache_v1alpha1_memcached.yaml
    ```
    `
    ```
    <br>
    Ensure your `kind: Memcached` Custom Resource (CR) is updated with `spec.size`

    <pre class="file">
    apiVersion: cache.example.com/v1alpha1
    kind: Memcached
    metadata:
      name: memcached-sample
    spec:
      size: 3
    </pre>

    You can easily update this file by running the following command:

    ```
    \cp /tmp/cache_v1alpha1_memcached.yaml config/samples/cache_v1alpha1_memcached.yaml
    ```
    `
    ```
    <br>
    Ensure you are currently scoped to the `myproject` Namespace:

    ```
    oc project myproject
    ```
    `
    ```
    <br>
    Deploy your PodSet Custom Resource to the live OpenShift Cluster:

    ```
    oc create -f config/samples/cache_v1alpha1_memcached.yaml
    ```
    `
    ```
    <br>
    Verify the memcached exists:

    ```
    oc get memcached
    ```
    `
    ```
    <br>
    Verify the Memcached operator has created 3 pods:

    ```
    oc get pods
    ```
    `
    ```
    <br>
    Verify that status shows the name of the pods currently owned by the Memcached:

    ```
    oc get memcached memcached-sample -o yaml
    ```
    `
    ```
    <br>
    Increase the number of replicas owned by the Memcached:

    ```
    oc patch memcached memcached-sample --type='json' -p '[{"op": "replace", "path": "/spec/size", "value":5}]'
    ```
    `
    ```
    <br>

    Verify that we now have 5 running pods
    ```
    oc get pods
    ```
    `
    ```
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
- slug: step12
  id: lyselou7ep38
  type: challenge
  title: Deleting the Memcached Custom Resource
  assignment: |-
    Our Memcached controller creates pods containing OwnerReferences in their `metadata` section. This ensures they will be removed upon deletion of the `memcached-sample` CR.

    Observe the OwnerReference set on a Memcached's pod:

    ```
    oc get pods -o yaml | grep ownerReferences -A10
    ```
    `
    ```
    <br>
    Delete the memcached-sample Custom Resource:

    ```
    oc delete memcached memcached-sample
    ```
    `
    ```

    Thanks to OwnerReferences, all of the pods should be deleted:

    ```
    oc get pods
    ```
    `
    ```
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 150
checksum: "6007475564141117903"
