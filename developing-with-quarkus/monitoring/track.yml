slug: developing-with-quarkus-monitoring
id: husayvyvw0ax
type: track
title: Monitoring Quarkus with Micrometer
description: |-
  This exercise demonstrates how your Quarkus application can utilize the [Micrometer Metrics](https://quarkus.io/guides/micrometer) extension to produce and observe metrics generated by the application.

  [Micrometer](https://micrometer.io/) allows applications to gather various metrics and statistics that provide insights into what is happening inside the application. They serve to pinpoint issues, provide long term trend data for capacity planning and pro-active discovery of issues (e.g. disk usage growing without bounds). Metrics can also help those scheduling systems decide when to scale the application to run on more or fewer machines.

  Micrometer defines a core library and a set of additional libraries that support different monitoring systems. Quarkus Micrometer extensions are structured similarly: quarkus-micrometer provides core micrometer support and runtime integration and other supporting Quarkus and Quarkiverse extensions bring in additional dependencies and requirements to support specific monitoring systems.

  ### Other possibilities

  Learn more at [quarkus.io](https://quarkus.io), or just drive on and get hands-on!
icon: https://logodix.com/logo/1910931.png
level: beginner
tags:
- openshift
owner: openshift
developers:
- btannous@redhat.com
- nvinto@redhat.com
- rjarvine@redhat.com
private: false
published: true
challenges:
- slug: 01-install-prometheus
  id: qzhlnbyc4yvi
  type: challenge
  title: Step 1
  assignment: |
    ## Login to OpenShift

    **Red Hat OpenShift Container Platform** is the preferred container orchestration platform for Quarkus. OpenShift is based on **Kubernetes** which is the most used Orchestration
    for containers running in production.

    In order to login, we will use the **oc** command and then specify the server that we
    want to authenticate to:

    ```
    oc login -u developer -p developer
    ```

    Congratulations, you are now authenticated to the OpenShift server.

    ## Access OpenShift Project

    [Projects](https://docs.openshift.com/container-platform/3.11/architecture/core_concepts/projects_and_users.html#projects)
    are a top level concept to help you organize your deployments. An
    OpenShift project allows a community of users (or a user) to organize and manage
    their content in isolation from other communities.

    For this scenario, let's create a project that you will use to house your applications. Click:

    ```
    oc new-project quarkus --display-name="Sample Monitored Quarkus App"
    ```

    ## Create Prometheus Configuration

    Next, let’s install Prometheus. Prometheus is an open-source systems monitoring and alerting toolkit featuring:

      - a multi-dimensional [data model](https://prometheus.io/docs/concepts/data_model/) with time series data identified by metric name and key/value pairs

      - [PromQL](https://prometheus.io/docs/prometheus/latest/querying/basics/), a flexible query language to leverage this dimensionality

      - time series collection happens via a pull model over HTTP

    To install it, first create a Kubernetes ConfigMap that will hold the Prometheus configuration. Click on the following command to create this file:

    ```
    cat <<EOF > /tmp/prometheus.yml
    global:
      scrape_interval:     15s
      evaluation_interval: 15s
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']
      - job_name: 'hello-app'
        metrics_path: '/q/metrics'
        static_configs:
        - targets: ['primes']
    EOF
    ```
    `
    ```

    This file contains basic Prometheus configuration, plus a specific `scrape_config` which instructs Prometheus to
    look for application metrics from both Prometheus itself, and a Quarkus app called `primes` (which we'll create later) at the `/q/metrics` endpoint.

    Next, click this command to create a ConfigMap with the above file:

    ```
    oc create configmap prom --from-file=prometheus.yml=/tmp/prometheus.yml
    ```

    ## Deploy Prometheus

    Next, deploy and expose Prometheus using its public Quay.io image:

    ```
    oc new-app quay.io/prometheus/prometheus && oc expose svc/prometheus
    ```

    And finally, mount the ConfigMap into the running container:

    ```
    oc set volume deployment/prometheus --add -t configmap --configmap-name=prom -m /etc/prometheus/prometheus.yml --sub-path=prometheus.yml
    ```

    This will cause the contents of the ConfigMap data to be mounted at `/etc/prometheus/prometheus.yml` inside its container
    where Prometheus is expecting it.

    Verify Prometheus is up and running:

    ```
    oc rollout status -w deployment/prometheus
    ```

    You should see `deployment "prometheus" successfully rolled out`.

    > If this command appears to hang, just press `CTRL-C` and click it again.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
- slug: 02-create-and-instrument-app
  id: yxupu4qgvwfm
  type: challenge
  title: Step 2
  assignment: |-
    # Inspect Java runtime and create basic project

    An appropriate Java runtime has been installed for you. Ensure you can use it by running this command:

    `$JAVA_HOME/bin/java --version`{{execute T1}}

    The command should report the version in use, for example (the versions and dates may be slightly different than the below example):

    ```console
    openjdk 11.0.10 2021-01-19
    OpenJDK Runtime Environment AdoptOpenJDK (build 11.0.10+9)
    OpenJDK 64-Bit Server VM AdoptOpenJDK (build 11.0.10+9, mixed mode)
    ```

    If the command fails, wait a few moments and try again (it is installed in a background process and make take a few moments depending on system load).

    ## Create basic project

    Let's create the basic Quarkus _Hello World_ application and include the necessary monitoring extensions. Click this command to create the project:

    `cd /root/projects/quarkus && \
    mvn io.quarkus:quarkus-maven-plugin:2.0.0.Final:create \
        -DprojectGroupId=org.acme \
        -DprojectArtifactId=primes \
        -DclassName="org.acme.quickstart.GreetingResource" \
        -Dextensions="micrometer-registry-prometheus" \
        -Dpath="/hello"`{{execute T1}}

    This will use the Quarkus Maven Plugin and generate a basic Maven project for you in the `primes` subdirectory and include the `micrometer-registry-prometheus` extension which causes the app to generate metrics at the `/q/metrics` endpoint.

    ## Start the app

    Change to the directory in which the app was created:

    `cd /root/projects/quarkus/primes`{{execute T1}}

    Let's begin Live Coding. Click on the following command to start the app in _Live Coding_ mode:

    `mvn quarkus:dev`{{execute T1}}

    You should see:

    ```console
    __  ____  __  _____   ___  __ ____  ______
     --/ __ \/ / / / _ | / _ \/ //_/ / / / __/
     -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\ \
    --\___\_\____/_/ |_/_/|_/_/|_|\____/___/
    INFO  [io.quarkus] (Quarkus Main Thread) primes 1.0.0-SNAPSHOT on JVM (powered by Quarkus x.xx.x.Final) started in x.xxxs. Listening on: http://localhost:8080
    INFO  [io.quarkus] (Quarkus Main Thread) Profile dev activated. Live Coding activated.
    INFO  [io.quarkus] (Quarkus Main Thread) Installed features: [cdi, micrometer, resteasy]

    --
    Tests paused, press [r] to resume, [h] for more options>
    ```

    > The first time you build the app, new dependencies may be downloaded via maven. This should only happen once, after that things will go even faster.

    Note the amazingly fast startup time! The app is now running "locally" (within the Linux container in which this exercise runs).

    Test that the app is running by accessing the simple `hello` endpoint:

    `cd /root/projects/quarkus/primes && \
      curl http://localhost:8080/hello`{{execute T2}}

    > You may need to click this command again in case it doesn't execute properly on first click

    you should see

    ```console
    Hello RESTEasy
    ```

    ## Test Metrics endpoint

    You will be able to immediately see the raw metrics generated from Quarkus apps. Run this in the Terminal:

    `curl http://localhost:8080/q/metrics`{{execute T2}}

    You will see a bunch of raw metrics in the OpenMetrics format (as we are using a Prometheus registry):

    ```console
    # TYPE http_server_bytes_read summary
    http_server_bytes_read_count 1.0
    http_server_bytes_read_sum 0.0
    # HELP http_server_bytes_read_max
    # TYPE http_server_bytes_read_max gauge
    http_server_bytes_read_max 0.0
    ```

    This is what Prometheus will do to access and index the metrics from our app when we deploy it to the cluster.

    ### Using other Registry Implementations

    It is possible to use other systems to consume metrics other than Prometheus, for example StackDriver (part of the [Quarkiverse](https://github.com/quarkiverse/quarkiverse-micrometer-registry)). You can also use other pre-packaged registries for other APM systems. Consult the [Quarkus Micrometer Guide](https://quarkus.io/guides/micrometer) for more detail.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
- slug: 03-add-additional-metrics
  id: mm661vee8vge
  type: challenge
  title: Step 3
  assignment: |+
    # Add additional metrics

    Out of the box, you get a lot of basic JVM metrics which are useful, but what if you wanted to provide metrics for your
    app? Let’s add a few using the Quarkus metrics APIs.

    Click here to open a new file `./primes/src/main/java/org/acme/quickstart/PrimeNumberResource.java`.

    This new class will implement an algorithm for checking whether a number is a prime number. This algorithm is exposed over a REST interface. With the Micrometer extension enabled, metrics for all http server requests are also collected automatically.

    We do want to add a few other metrics to demonstrate how to add and filter metrics:

    * A counter will be incremented for every prime number discovered
    * A gauge will store the highest prime number discovered
    * A timer will record the time spent testing if a number is prime.

    Click **Copy To Editor** to create the code for our new class:

    <pre class="file" data-filename="./primes/src/main/java/org/acme/quickstart/PrimeNumberResource.java" data-target="replace">
    package org.acme.quickstart;

    import io.micrometer.core.instrument.MeterRegistry;

    import javax.ws.rs.GET;
    import javax.ws.rs.Path;
    import javax.ws.rs.PathParam;
    import javax.ws.rs.Produces;
    import javax.ws.rs.core.MediaType;
    import java.util.concurrent.atomic.LongAccumulator;
    import java.util.function.Supplier;

    @Path(&quot;/is-prime&quot;)
    public class PrimeNumberResource {

        private final LongAccumulator highestPrime = new LongAccumulator(Long::max, 0);
        private final MeterRegistry registry;

        PrimeNumberResource(MeterRegistry registry) {
            this.registry = registry;

            // Create a gauge that uses the highestPrimeNumberSoFar method
            // to obtain the highest observed prime number
            registry.gauge(&quot;prime.number.max&quot;, this,
                    PrimeNumberResource::highestObservedPrimeNumber);
        }

        @GET
        @Path(&quot;/{number}&quot;)
        @Produces(MediaType.TEXT_PLAIN)
        public String checkIfPrime(@PathParam(&quot;number&quot;) long number) {
            if (number &lt; 1) {
                return &quot;Only natural numbers can be prime numbers.&quot;;
            }
            if (number == 1) {
                return &quot;1 is not prime.&quot;;
            }
            if (number == 2) {
                return &quot;2 is prime.&quot;;
            }
            if (number % 2 == 0) {
                return number + &quot; is not prime, it is divisible by 2.&quot;;
            }

            Supplier&lt;String&gt; supplier = () -&gt; {
                for (int i = 3; i &lt; Math.floor(Math.sqrt(number)) + 1; i = i + 2) {
                    if (number % i == 0) {
                        return number + &quot; is not prime, is divisible by &quot; + i + &quot;.&quot;;
                    }
                }
                highestPrime.accumulate(number);
                return number + &quot; is prime.&quot;;
            };

            return registry.timer(&quot;prime.number.test&quot;).wrap(supplier).get();
        }

        /**
         * This method is called by the registered {@code highest.prime.number} gauge.
         * @return the highest observed prime value
         */
        long highestObservedPrimeNumber() {
            return highestPrime.get();
        }
    }
    </pre>

    Let's test it out by accessing the new endpoint with a few prime and non-prime numbers:

    Click the following commands to test whether the number is a prime number:

    `curl http://localhost:8080/is-prime/1`{{execute T2}}

    You should see `1 is not prime.`.

    `curl http://localhost:8080/is-prime/350`{{execute T2}}

    You should see `350 is not prime, it is divisible by 2.`.

    `curl http://localhost:8080/is-prime/629521085409773`{{execute T2}}

    You should see `629521085409773 is prime.`.

    `curl http://localhost:8080/is-prime/1111111111111111111`{{execute T2}}

    You should see `1111111111111111111 is prime.`.

    Each command will output whether the number is prime or not. The last two commands will take considerably longer (up to 5-10 seconds) as these are large prime numbers (that also form [the basis](https://access.redhat.com/blogs/766093/posts/2177481) of modern internet security!).

    Review the metrics generated so far to see them in action:

    `curl http://localhost:8080/q/metrics`{{execute T2}}

    You'll see many metrics, for example:

    ```
    # HELP prime_number_max
    # TYPE prime_number_max gauge
    prime_number_max 887.0
    # TYPE http_server_requests_seconds summary
    http_server_requests_seconds_count{method="GET",outcome="SUCCESS",status="200",uri="/is-prime/{number}",} 4.0
    http_server_requests_seconds_sum{method="GET",outcome="SUCCESS",status="200",uri="/is-prime/{number}",} 0.082716484
    ```

    You can also display only our "prime"-related metrics:

    `curl -s http://localhost:8080/q/metrics | grep -i prime`{{execute T2}}

    > **NOTE**: Metrics are generated lazily, so you often won’t see any data for your endpoint until something tries to access it!

    > **NOTE**: You can optionally enable the [JSON exporter](https://quarkus.io/guides/micrometer#quarkus-micrometer_quarkus.micrometer.export.json.enabled) to output metrics as JSON-formatted objects. One enabled, requests must pass the `Accept: application/json` HTTP header to get JSON metrics.

    ## Configuring and Filtering Metrics

    Micrometer uses `MeterFilter` instances to customize the metrics emitted by `MeterRegistry` instances. The Micrometer extension will detect `MeterFilter` CDI beans and use them when initializing `MeterRegistry` instances. These can be used to exercise greater control over how and when meters are registered and what kinds of statistics they emit. Meter filters serve three basic functions:

    * **Deny** (or accept) meters from being registered.
    * **Transform** meter IDs (e.g. changing the name, adding or removing tags, changing description or base units).
    * **Configure** distribution statistics for some meter types (e.g. timers)

    To create MeterFilters, you can simply declare them using annotations in your code. Quarkus will identify and inject them into `MeterRegistry`s as they are created, based on criteria specified in the annotations.

    Click here to open a new file `primes/src/main/java/org/acme/quickstart/CustomConfiguration.java`.

    Click **Copy To Editor** to create the code for our new class:

    <pre class="file" data-filename="./primes/src/main/java/org/acme/quickstart/CustomConfiguration.java" data-target="replace">
    package org.acme.quickstart;

    import java.util.Arrays;

    import javax.annotation.Priority;
    import javax.inject.Singleton;
    import javax.interceptor.Interceptor;
    import javax.enterprise.inject.Produces;

    import org.eclipse.microprofile.config.inject.ConfigProperty;

    import io.micrometer.core.instrument.Clock;
    import io.micrometer.core.instrument.Meter;
    import io.micrometer.core.instrument.Tag;
    import io.micrometer.core.instrument.config.MeterFilter;
    import io.micrometer.core.instrument.distribution.DistributionStatisticConfig;
    import io.micrometer.prometheus.PrometheusConfig;
    import io.micrometer.prometheus.PrometheusMeterRegistry;
    import io.prometheus.client.CollectorRegistry;
    import io.quarkus.micrometer.runtime.MeterFilterConstraint;

    @Singleton
    public class CustomConfiguration {

        @ConfigProperty(name = &quot;deployment.env&quot;)
        String deploymentEnv;

        @Produces
        @Singleton
        @MeterFilterConstraint(applyTo = PrometheusMeterRegistry.class)
        public MeterFilter configurePrometheusRegistries() {
            return MeterFilter.commonTags(Arrays.asList(
                    Tag.of(&quot;registry&quot;, &quot;prometheus&quot;)));
        }

        @Produces
        @Singleton
        public MeterFilter configureAllRegistries() {
            return MeterFilter.commonTags(Arrays.asList(
                    Tag.of(&quot;env&quot;, deploymentEnv)));
        }

        /** Enable histogram buckets for a specific timer */
        @Produces
        @Singleton
        public MeterFilter enableHistogram() {
            return new MeterFilter() {
                @Override
                public DistributionStatisticConfig configure(Meter.Id id, DistributionStatisticConfig config) {
                    if(id.getName().startsWith(&quot;prime&quot;)) {
                        return DistributionStatisticConfig.builder()
                            .percentiles(0.5, 0.95)     // median and 95th percentile, not aggregable
                            .percentilesHistogram(true) // histogram buckets (e.g. prometheus histogram_quantile)
                            .build()
                            .merge(config);
                    }
                    return config;
                }
            };
        }
    }
    </pre>

    These do the following:

    * **`configurePrometheusRegistries`** - Adds custom tag of `registry: prometheus` to Prometheus registry metrics
    * **`configureAllRegistries`** Adds a custom tag of `env: [value]` using the value of the `ConfigProperty` named `deploymentEnv` (which must be present in your `application.properties`)
    * **`enableHistogram`** - This enables any timer metric whose name begins with `prime` to report additional quantile metrics (mean, median, and other custom histograms)

    Filtering and tagging can be useful to organize the reporting, so you can more easily draw conclusions about data.

    Finally, you need to add the configuration value referenced in the `configureAllRegistries` filter to your `application.properties`.

    Click here to open the file (it will be empty): `primes/src/main/resources/application.properties`.

    Then click **Copy to Editor** to add the following values to the `application.properties` file:

    <pre class="file" data-filename="./src/main/resources/application.properties" data-target="replace">
    # Configure value for the tag we add to metrics
    deployment.env=prod

    </pre>

    This will cause a tag `env: prod` to be added to each metric based on our above filter.

    ## Test new metrics

    Let's do a quick test and make sure they're working. Access the endpoint a couple more times by clicking on the below commands:

    `curl http://localhost:8080/is-prime/350`{{execute T2}}

    `curl http://localhost:8080/is-prime/629521085409773`{{execute T2}}

    Now let's see if it worked. Let's look for our `prime` metrics with this command:

    `curl -s http://localhost:8080/q/metrics | grep prime`{{execute T2}}

    You should see new types of quantile metrics along with our new `env` and `registry` tags:

    ```console
    prime_number_test_seconds{env="prod",registry="prometheus",quantile="0.5",} 0.0
    prime_number_test_seconds{env="prod",registry="prometheus",quantile="0.95",} 0.0
    prime_number_test_seconds_bucket{env="prod",registry="prometheus",le="0.001",} 0.0
    prime_number_test_seconds_bucket{env="prod",registry="prometheus",le="0.001048576",} 0.0
    prime_number_test_seconds_bucket{env="prod",registry="prometheus",le="0.001398101",} 0.0
    prime_number_test_seconds_bucket{env="prod",registry="prometheus",le="0.001747626",} 0.0
    ...
    ```

    It's not that fun to read the raw output, it'd be better if we had a better way to manage the monitoring of these metrics. Let's do that with Prometheus and OpenShift!

    ## Cleanup

    We're done coding, so let's stop the app. In the first Terminal, press `CTRL-C` to stop the running Quarkus app (or click the `clear`{{execute T1 interrupt}} command to do it for you).

  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
- slug: 04-deploy-to-openshift
  id: r3yeujfyzktx
  type: challenge
  title: Step 4
  assignment: |-
    Now that we have our app built, let's move it into containers and into the cloud where Prometheus can scrape from.

    ## Install OpenShift extension

    Quarkus offers the ability to automatically generate OpenShift resources based on sane default and user supplied configuration. The OpenShift extension is actually a wrapper extension that brings together the [kubernetes](https://quarkus.io/guides/deploying-to-kubernetes) and [container-image-s2i](https://quarkus.io/guides/container-image#s2i) extensions with defaults so that it’s easier for the user to get started with Quarkus on OpenShift.

    Run the following command to add it to our project:

    `mvn quarkus:add-extension -Dextensions="openshift"`{{execute T1}}

    Open here to add OpenShift properties: `primes/src/main/resources/application.properties`.

    Then click **Copy to Editor** to add the following values to the `application.properties` file:

    <pre class="file" data-filename="./src/main/resources/application.properties" data-target="append">
    # Configure the OpenShift extension options
    quarkus.kubernetes-client.trust-certs=true
    quarkus.container-image.build=true
    quarkus.kubernetes.deploy=true
    quarkus.kubernetes.deployment-target=openshift
    quarkus.openshift.expose=true
    quarkus.openshift.labels.app.openshift.io/runtime=quarkus

    </pre>

    For more details of the above options:

    * `quarkus.kubernetes-client.trust-certs=true` - We are using self-signed certs in this simple example, so this simply says to the extension to trust them.
    * `quarkus.container-image.build=true` - Instructs the extension to build a container image
    * `quarkus.kubernetes.deploy=true` - Instructs the extension to deploy to OpenShift after the container image is built
    * `quarkus.kubernetes.deployment-target=openshift` - Instructs the extension to generate and create the OpenShift resources (like `DeploymentConfig`s and `Service`s) after building the container
    * `quarkus.openshift.route.expose=true` - Instructs the extension to generate an OpenShift `Route`.
    * `quarkus.openshift.labels.app.openshift.io/runtime=quarkus` - Adds a nice-looking icon to the app when viewing the OpenShift Developer Toplogy

    ## Deploy to OpenShift

    Now let's deploy the application itself. Run the following command which will build and deploy using the OpenShift extension (it will take a minute or two):

    `mvn clean package -DskipTests`{{execute T1}}

    > **NOTE**: This command will take a minute or two, as it builds the app, pushes a container image, and finally deploys the container to OpenShift.

    The output should end with `BUILD SUCCESS`.

    Finally, make sure it's actually done rolling out:

    `oc rollout status -w dc/primes`{{execute T1}}

    Wait for that command to report `replication controller "primes-1" successfully rolled out` before continuing.

    You can also see the app deployed in the [OpenShift Developer Toplogy](https://console-openshift-console-[[HOST_SUBDOMAIN]]-443-[[KATACODA_HOST]].environments.katacoda.com/topology/ns/quarkus):

    You'll need to login with the same credentials as before:

    * Username: `developer`
    * Password: `developer`

    ![Deployed App](/openshift/assets/middleware/quarkus/primedep.png)

    And now we can access using `curl` once again to test our prime service running on OpenShift. Click the commands to access the app on OpenShift:

    ```
    curl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/1
    ```

    ```
    curl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/350
    ```

    `curl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/629521085409773`{{execute T1}}

    With our app rolled out, Prometheus should start collecting metrics. Let's take a look in the next exercise.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
- slug: 05-query-with-prometheus
  id: kxumdkiqimza
  type: challenge
  title: Step 4
  assignment: |-
    ## Generate Load

    We will use the open source [OpenSSL](https://www.openssl.org/) project to generate some test primes to exercise our app. Click the following command to verify openssl is installed. If it is not, you may need to wait a few seconds and click the command again until it reports a proper version

    `openssl version`{{execute T1}}

    Then you should see

    ```console
    OpenSSL 1.1.1g FIPS  21 Apr 2020
    ```

    With our app deployed to OpenShift, let's setup a loop that will test random numbers for primeness. Click the following command to endlessly run `curl` every 2 seconds with a random prime number:

    `while [ true ] ; do
            BITS=$(( ( RANDOM % 60 )  + 1 ))
            NUM=$(openssl prime -generate -bits $BITS)
            curl http://primes-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/is-prime/${NUM}
            sleep 2
    done`{{execute T1}}

    With that running, click on this link to [open up the Prometheus dashboard](http://prometheus-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/). You'll see the Prometheus UI:

    ![Prometheus UI](/openshift/assets/middleware/quarkus/prom.png)

    Within about 15-30 seconds, Prometheus should start scraping the metrics. Start typing in the query box to look for `prime`:

    > **Note**
    >
    > If you do not see any `prime` metrics when querying, wait 15 seconds, reload the Prometheus page, and try again. They
    > will eventually show up\!

    ![Prometheus UI](/openshift/assets/middleware/quarkus/promnames.png)

    Type `prime` in the query, and select `prime_number_max` in the box, and click **Execute**. This will
    fetch the values from our metric showing the largest prime number found so far:

    ![Prometheus UI](/openshift/assets/middleware/quarkus/promchecks.png)

    Cool\! You can try this with some of the standard HTTP metrics as well, e.g. try to graph the `http_server_requests_seconds_count` to
    see how often our various HTTP endpoints are accessed. You can see the endpoints shown with different colors, one for each endpoint (`/is-prime/{number}`, `/q/metrics`, and the 404 not-found endpoint).

    ![Prometheus UI](/openshift/assets/middleware/quarkus/promgraph.png)


    Keep the `curl` loop running and we'll move on to build a full dashboard for our app in the next step.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
- slug: 06-install-grafana
  id: 76hxxkokrmyz
  type: challenge
  title: Step 5
  assignment: |+
    # Install Grafana

    We'll keep our prime number checker running. Click to run the following command in the other Terminal to deploy Grafana to our cluster:

    `oc new-app quay.io/bitnami/grafana && oc expose svc/grafana`{{execute T2}}

    > It may take up to a minute to finish deploying

    Verify Grafana is up and running:

    ```
    oc rollout status -w deployment/grafana
    ```

    You should see `replication controller "grafana-1" successfully rolled out`

    # Open Grafana Dashboard

    Click on this link to [open the Grafana Dashboard in your browser](http://grafana-quarkus.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com/), and login using the default credentails:

      - Username: `admin`
      - Password: `admin`

    ![Grafana UI](/openshift/assets/middleware/quarkus/graflogin.png)

    At the password change prompt, use any password you wish.

    # Add Prometheus as a data source

    You’ll land on the Data Source screen. Click **Add your first data source**, and click **Select** next to **Prometheus** as the *Data Source Type*.

    In the URL box, type ``http://prometheus:9090`` (this is the hostname and port of our running Prometheus in our
    namespace):

    > **WARNING**
    >
    > If you skip this step, you'll get errors and things won't work! Make sure to change it to ``http://prometheus:9090``!

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafds.png)

    Click **Save and Test**. You should see:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafworking.png)

    With our data source working, let’s make a dashboard.

  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
- slug: 07-create-dashboard
  id: 7maxxw8mzje3
  type: challenge
  title: Step 6
  assignment: |
    # Create Dashboard

    In the Grafana Dashboard, hover over the `+` button on the left, and select *Create \> Dashboard*:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafcreate.png)

    Next, click **Add an Empty Panel**.

    This will create a new dashboard with a single Panel. Each Panel can visualize a computed metric (either a single
    metric, or a more complex query) and display the results in the Panel.

    In the _Metrics_ box, type `prime` to again get an autocompleted list of available metrics that match that name:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafquery.png)

    Choose from the drop-down `prime_number_test_seconds_max`. Then click on the **Refresh** button to begin to show in the graph above:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafgraf.png)

    This is querying the custom `prime.number.test` metric from our earlier Java code we created. With the `seconds_max` suffix it will show the max # of seconds taken to calculate a prime from our `curl` loop still running.

    > **Note**: Statistics like max, percentiles, and histogram counts decay over time to give greater weight to recent samples, so you'll see even the `max` value going up and down as older values drop out of the rolling window of samples.

    Next click on the *Visualization* section on the right:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafvis.png)

    This lets you fine tune the display, along with the type of graph (bar, line, gauge, etc). Leave them for now, and look up in the _Settings_ section above, and change the name of the panel to `Prime Time`.

    ![Grafana UI](/openshift/assets/middleware/quarkus/graftitle.png)

    There is an *Alerts* tab you can configure to send alerts (email, etc) when conditions are met for this and other
    queries. We’ll skip this for now.

    Click *Save* at the top right to save our new dashboard and give it a name such as _My Prime Dashboard_.

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafsave.png)

    # Add more Panels

    See if you can add additional Panels. Use the **Add Panel** button to add a new Panel:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafmorepanels.png)

    Follow the same steps as before to create a few more panels, and **don’t forget to Save each panel when you’ve created
    it.**

    Add Panels for:

      - The HTTP endpoint timers `http_server_requests_seconds_count` (name it "Primes HTTP Timer" on the *General* tab).
      - The RSS Memory used by the app `process_resident_memory_bytes` (set the title to `RSS Memory` on the *General* tab.

    To see the quantile metrics, create another panel for the `prime_number_test_seconds_bucket` metric. When you select that metric in Grafana, it will notice you'll want a histogram panel, so click the helpful tip to show the 95% quantile:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafhist.png)

    The graph will update to show the 95% quantile of the time it takes to evaluate whether a number is prime or not:

    ![Grafana UI](/openshift/assets/middleware/quarkus/grafhistdata.png)

    # Fix layout

    After saving, go back to the main dashboard (click on **Quar** at the top and then select it under *Recent
    Dashboards*). Change the time value to *Last 15 Minutes* at the top-right:

    ![time](/openshift/assets/middleware/quarkus/graftime.png)

    Finally, drag and resize the different panels to look nice and fit on a single page.

    Click **Save Dashboad** again to save it. Your final Dashboard should look like:

    ![final](/openshift/assets/middleware/quarkus/graffinal.png)

    You can add many more metrics to monitor and alert for Quarkus apps using these tools.

    # Open the solution in an IDE in the Cloud!
    Want to continue exploring this solution on your own in the cloud? You can use the free [Red Hat CodeReady Workspaces](https://developers.redhat.com/products/codeready-workspaces/overview) IDE running on the free [Red Hat Developer Sandbox](http://red.ht/dev-sandbox). [Click here](https://workspaces.openshift.com) to login or to register if you are a new user. This free service expires after 30 days, but you can always enable a new free 30-day subscription.

    Once logged in, [click here](https://workspaces.openshift.com/f?url=https://raw.githubusercontent.com/openshift-katacoda/rhoar-getting-started/solution/quarkus/monitoring/devfile.yaml) to open the solution for this project in the cloud IDE. While loading, if it asks you to update or install any plugins, you can say no.

    # Fork the source code to your own GitHub!
    Want to experiment more with the solution code you just worked with? If so, you can fork the repository containing the solution to your own GitHub repository by clicking on the following command to execute it:

    `/root/projects/forkrepo.sh`{{execute T1}}
    - Make sure to follow the prompts. An error saying `Failed opening a web browser at https://github.com/login/device exit status 127` is expected.
    - [Click here](https://github.com/login/device) to open a new browser tab to GitHub and paste in the code you were presented with and you copied.
    - Once done with the GitHub authorization in the browser, close the browser tab and return to the console and press `Enter` to complete the authentication process.
    - If asked to clone the fork, press `n` and then `Enter`.
    - If asked to confirm logout, press `y` and the `Enter`.

       > **NOTE:** This process uses the [GitHub CLI](https://cli.github.com) to authenticate with GitHub. The learn.openshift.com site is not requesting nor will have access to your GitHub credentials.

    After completing these steps the `rhoar-getting-started` repo will be forked in your own GitHub account. On the `solution` branch in the repo, the `monitoring` project inside the `quarkus` folder contains the completed solution for this scenario.

    # Congratulations\!

    This exercise demonstrates how your Quarkus application can utilize the [Micrometer
    Metrics extension](https://quarkus.io/guides/micrometer) to visualize metrics for Quarkus applications. You also
    consumed these metrics using a popular monitoring stack with Prometheus and Grafana and other APM tools that support Micrometer.

    There are many more possibilities for application metrics, and it’s a useful way to not only gather metrics, but act on
    them through alerting and other features of the monitoring stack you may be using.
  tabs:
  - title: CLI
    type: terminal
    hostname: crc-nonest-1
  - title: OpenShift Web Console
    type: service
    hostname: crc-nonest-1
    port: 30443
  - title: Visual Editor
    type: code
    hostname: crc-nonest-1
    path: /root
  difficulty: basic
  timelimit: 128
checksum: "2612468204413170261"
